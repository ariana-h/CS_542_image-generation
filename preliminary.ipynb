{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc612af-d732-4091-842b-9432e2228911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "import os\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67400ca5-541a-4fb9-950b-1f9aa8f20e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder_path = 'img_align_celeba'\n",
    "destination_folder_path = 'train_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3408a817-29d3-4a72-bd53-fd6b0a9e171b",
   "metadata": {},
   "source": [
    "Resize images so that training and generation does not take as long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30000024-61b0-4923-8ecd-0b0f690bc61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_save_images(source_folder, destination_folder, target_size):\n",
    "    if not os.path.exists(source_folder):\n",
    "        print(f\"Source folder '{source_folder}' does not exist.\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(source_folder):\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "        image = cv2.imread(source_path)\n",
    "\n",
    "        if image is not None:\n",
    "            resized_image = cv2.resize(image, target_size)\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            cv2.imwrite(destination_path, resized_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9dd14f-dded-4490-aef9-dc098434549b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_size = (64, 64)\n",
    "\n",
    "resize_and_save_images(source_folder_path, destination_folder_path, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e905ad9b-200f-4bbe-aa6d-dd826df4c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arian\\.conda\\envs\\cs542ml\\Lib\\site-packages\\diffusers\\utils\\outputs.py:63: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from diffusers import UNet2DModel, DDPMScheduler, DDPMPipeline\n",
    "from diffusers.utils import make_image_grid, pt_to_pil\n",
    "from dataclasses import dataclass\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "import tqdm\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from diffusers.utils import pt_to_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2842e4c-e4c6-42bc-bf4a-3cea0c5dec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 64\n",
    "    train_batch_size = 16\n",
    "    eval_batch_size = 16\n",
    "    mixed_precision = \"fp16\"\n",
    "    output_dir = \"gen_model\"\n",
    "    gradient_accumulation_steps = 1\n",
    "    start_epoch = 0\n",
    "    total_epochs = 100\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    save_image_epochs = 10\n",
    "    save_model_epochs = 20\n",
    "    overwrite_output_dir = True\n",
    "    seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc07959-9f0f-4eed-9ec3-c9e74dab719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, folder_path, transform=None):\n",
    "        self.folder_path = folder_path\n",
    "        self.transform = transform\n",
    "        self.image_list = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_list[idx]\n",
    "        images = cv2.imread(img_path)\n",
    " \n",
    "        if self.transform:\n",
    "            images = self.transform(images)\n",
    "\n",
    "        return {\"images\": images}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "966bccf0-4282-4924-8c66-ddf3d6145bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = TrainingConfig()\n",
    "    \n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((config.image_size, config.image_size)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "dataset = ImageDataset('train_images', transform=transform)\n",
    "    \n",
    "dataloader = DataLoader(dataset,\n",
    "                        batch_size=config.train_batch_size,\n",
    "                        shuffle=True)\n",
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "           else \"mps\" if torch.backends.mps.is_available()\n",
    "           else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f4946f3-e045-4d91-b79c-57611c9d45a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2DModel(\n",
      "  (conv_in): Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (time_proj): Timesteps()\n",
      "  (time_embedding): TimestepEmbedding(\n",
      "    (linear_1): LoRACompatibleLinear(in_features=128, out_features=512, bias=True)\n",
      "    (act): SiLU()\n",
      "    (linear_2): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "  )\n",
      "  (down_blocks): ModuleList(\n",
      "    (0-1): 2 x DownBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=128, bias=True)\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): DownBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=256, bias=True)\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=256, bias=True)\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): DownBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=256, bias=True)\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): AttnDownBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-1): 2 x Attention(\n",
      "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (to_out): ModuleList(\n",
      "            (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "      (downsamplers): ModuleList(\n",
      "        (0): Downsample2D(\n",
      "          (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): DownBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_blocks): ModuleList(\n",
      "    (0): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-2): 3 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): AttnUpBlock2D(\n",
      "      (attentions): ModuleList(\n",
      "        (0-2): 3 x Attention(\n",
      "          (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (to_out): ModuleList(\n",
      "            (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "            (1): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 1024, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 768, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(768, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 768, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=256, bias=True)\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=256, bias=True)\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-1): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=256, bias=True)\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (2): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=256, bias=True)\n",
      "          (norm2): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): LoRACompatibleConv(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0): ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 384, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=128, bias=True)\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(384, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (1-2): 2 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=128, bias=True)\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "      (upsamplers): ModuleList(\n",
      "        (0): Upsample2D(\n",
      "          (conv): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): UpBlock2D(\n",
      "      (resnets): ModuleList(\n",
      "        (0-2): 3 x ResnetBlock2D(\n",
      "          (norm1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
      "          (conv1): LoRACompatibleConv(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=128, bias=True)\n",
      "          (norm2): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (conv2): LoRACompatibleConv(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "          (nonlinearity): SiLU()\n",
      "          (conv_shortcut): LoRACompatibleConv(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mid_block): UNetMidBlock2D(\n",
      "    (attentions): ModuleList(\n",
      "      (0): Attention(\n",
      "        (group_norm): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (to_q): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "        (to_k): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "        (to_v): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "        (to_out): ModuleList(\n",
      "          (0): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "          (1): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (resnets): ModuleList(\n",
      "      (0-1): 2 x ResnetBlock2D(\n",
      "        (norm1): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (conv1): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (time_emb_proj): LoRACompatibleLinear(in_features=512, out_features=512, bias=True)\n",
      "        (norm2): GroupNorm(32, 512, eps=1e-05, affine=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (conv2): LoRACompatibleConv(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_norm_out): GroupNorm(32, 128, eps=1e-05, affine=True)\n",
      "  (conv_act): SiLU()\n",
      "  (conv_out): Conv2d(128, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = UNet2DModel(\n",
    "    in_channels = 3,\n",
    "    out_channels = 3,\n",
    "    sample_size = config.image_size,\n",
    "    layers_per_block = 2,\n",
    "    block_out_channels = (128,128,256,256,512,512),\n",
    "    down_block_types = [\n",
    "        \"DownBlock2D\",\"DownBlock2D\",\n",
    "        \"DownBlock2D\",\"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"DownBlock2D\"\n",
    "    ],\n",
    "    up_block_types = [\n",
    "        \"UpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\"UpBlock2D\",\"UpBlock2D\",\"UpBlock2D\"\n",
    "    ]        \n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8484521-8912-4858-a8a7-24ab9eaa4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "optimizer = torch.optim.AdamW(model.parameters(),\n",
    "                              lr=config.learning_rate)\n",
    "    \n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(len(dataloader)*config.total_epochs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1b31212-f555-495e-939e-bd9d96ff9631",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filename = os.path.join(config.output_dir,\n",
    "                                   \"checkpoint.pt\")\n",
    "config.start_epoch = 0\n",
    "if os.path.exists(checkpoint_filename):\n",
    "    checkpoint = torch.load(checkpoint_filename)\n",
    "    config.start_epoch = checkpoint[\"epoch\"]+1\n",
    "    model.load_state_dict(checkpoint[\"network\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    lr_scheduler.load_state_dict(checkpoint[\"lr_scheduler\"])\n",
    "    print(\"Loading previous checkpoint...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48ae42d7-8da2-4f5b-b227-72ad982d4e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(config, epoch, pipeline):\n",
    "    images = pipeline(\n",
    "        batch_size=config.eval_batch_size,\n",
    "        generator=torch.manual_seed(config.seed)\n",
    "    ).images\n",
    "        \n",
    "    image_grid = make_image_grid(images, 4, 4)\n",
    "        \n",
    "    test_dir = os.path.join(config.output_dir, \"samples\")\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    image_grid.save(os.path.join(test_dir,\n",
    "                                 \"Image_%04d.png\" % epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12dec547-817e-40fb-a830-eef23ea4dfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(config, model, optimizer,\n",
    "               noise_scheduler, dataloader,\n",
    "               lr_scheduler):\n",
    "        \n",
    "    accelerator = Accelerator(\n",
    "        mixed_precision=config.mixed_precision,\n",
    "        gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
    "        log_with=\"tensorboard\",\n",
    "        project_dir=os.path.join(config.output_dir, \"logs\")\n",
    "    )\n",
    "        \n",
    "    (model,\n",
    "     optimizer,\n",
    "     dataloader,\n",
    "     noise_scheduler,\n",
    "     lr_scheduler) = accelerator.prepare(\n",
    "                                        model,\n",
    "                                        optimizer,\n",
    "                                        dataloader,\n",
    "                                        noise_scheduler,\n",
    "                                        lr_scheduler\n",
    "                                        )\n",
    "         \n",
    "    if accelerator.is_main_process:\n",
    "        os.makedirs(config.output_dir, exist_ok=True)\n",
    "        accelerator.init_trackers(\"training\")  \n",
    "        \n",
    "    global_step = 0\n",
    "        \n",
    "    for epoch in range(config.start_epoch,\n",
    "                       config.total_epochs):        \n",
    "        progress_bar = tqdm.tqdm(total=len(dataloader),\n",
    "                                 disable=not accelerator.is_main_process)\n",
    "        progress_bar.set_description(f\"Epoch {epoch}\")\n",
    "            \n",
    "        for batch in dataloader:\n",
    "            clean_images = batch[\"images\"]   \n",
    "                \n",
    "                \n",
    "            noise = torch.randn(clean_images.shape).to(\n",
    "                           clean_images.device)\n",
    "            bs = clean_images.shape[0]\n",
    "            timesteps = torch.randint(0,\n",
    "                            noise_scheduler.config.num_train_timesteps,\n",
    "                            (bs,),\n",
    "                            device=clean_images.device).long()\n",
    "            noisy_images = noise_scheduler.add_noise(\n",
    "                    clean_images,\n",
    "                    noise,\n",
    "                    timesteps\n",
    "            )\n",
    "                                             \n",
    "                \n",
    "            with accelerator.accumulate(model):\n",
    "                noise_pred = model(noisy_images,\n",
    "                                   timesteps,\n",
    "                                   return_dict=False)[0]\n",
    "                loss = torch.nn.functional.mse_loss(noise_pred, noise)\n",
    "                    \n",
    "                accelerator.backward(loss)\n",
    "                accelerator.clip_grad_norm_(model.parameters(),1.0)\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            progress_bar.update(1)\n",
    "            logs = {\n",
    "                \"loss\": loss.detach().item(),\n",
    "                \"step\": global_step,\n",
    "                \"lr\": lr_scheduler.get_last_lr()[0]                     \n",
    "            }\n",
    "            progress_bar.set_postfix(**logs)\n",
    "            accelerator.log(logs, step=global_step)\n",
    "            global_step += 1\n",
    "                \n",
    "        if accelerator.is_main_process:\n",
    "            pipeline = DDPMPipeline(\n",
    "                unet=accelerator.unwrap_model(model),\n",
    "                scheduler=noise_scheduler)\n",
    "\n",
    "            if(epoch+1)%config.save_image_epochs == 0:\n",
    "                evaluate(config, epoch, pipeline)\n",
    "                                                     \n",
    "            if(epoch+1)%config.save_model_epochs == 0:\n",
    "                pipeline.save_pretrained(config.output_dir)\n",
    "\n",
    "                unwrapped = accelerator.unwrap_model(model)\n",
    "                save_info = {\n",
    "                    \"epoch\": epoch,\n",
    "                    \"network\": unwrapped.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"lr_scheduler\": lr_scheduler.state_dict()                \n",
    "                }\n",
    "                torch.save(save_info, checkpoint_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ea01e43-d0e8-43a4-9ff4-157968628791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on CPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                              | 0/10822 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:   0%|                                                                     | 0/10822 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:   0%|                                                         | 1/10822 [00:54<162:56:21, 54.21s/it]\u001b[A\n",
      "Epoch 0:   0%|                             | 1/10822 [00:54<162:56:21, 54.21s/it, loss=1.05, lr=2e-7, step=0]\u001b[A\n",
      "Epoch 0:   0%|                             | 2/10822 [01:40<149:23:27, 49.70s/it, loss=1.05, lr=2e-7, step=0]\u001b[A\n",
      "Epoch 0:   0%|                             | 2/10822 [01:40<149:23:27, 49.70s/it, loss=1.04, lr=4e-7, step=1]\u001b[A\n",
      "Epoch 0:   0%|                             | 3/10822 [02:16<130:24:15, 43.39s/it, loss=1.04, lr=4e-7, step=1]\u001b[A\n",
      "Epoch 0:   0%|                             | 3/10822 [02:16<130:24:15, 43.39s/it, loss=1.05, lr=6e-7, step=2]\u001b[A\n",
      "Epoch 0:   0%|                             | 4/10822 [02:52<121:19:29, 40.37s/it, loss=1.05, lr=6e-7, step=2]\u001b[A\n",
      "Epoch 0:   0%|                             | 4/10822 [02:52<121:19:29, 40.37s/it, loss=1.03, lr=8e-7, step=3]\u001b[A\n",
      "Epoch 0:   0%|                             | 5/10822 [03:28<116:22:45, 38.73s/it, loss=1.03, lr=8e-7, step=3]\u001b[A\n",
      "Epoch 0:   0%|                             | 5/10822 [03:28<116:22:45, 38.73s/it, loss=1.04, lr=1e-6, step=4]\u001b[A\n",
      "Epoch 0:   0%|                             | 6/10822 [04:03<112:40:19, 37.50s/it, loss=1.04, lr=1e-6, step=4]\u001b[A\n",
      "Epoch 0:   0%|                           | 6/10822 [04:03<112:40:19, 37.50s/it, loss=1.04, lr=1.2e-6, step=5]\u001b[A\n",
      "Epoch 0:   0%|                           | 7/10822 [04:42<113:59:08, 37.94s/it, loss=1.04, lr=1.2e-6, step=5]\u001b[A\n",
      "Epoch 0:   0%|                           | 7/10822 [04:42<113:59:08, 37.94s/it, loss=1.04, lr=1.4e-6, step=6]\u001b[A\n",
      "Epoch 0:   0%|                           | 8/10822 [05:21<115:01:12, 38.29s/it, loss=1.04, lr=1.4e-6, step=6]\u001b[A\n",
      "Epoch 0:   0%|                           | 8/10822 [05:21<115:01:12, 38.29s/it, loss=1.04, lr=1.6e-6, step=7]\u001b[A\n",
      "Epoch 0:   0%|                           | 9/10822 [06:09<124:06:08, 41.32s/it, loss=1.04, lr=1.6e-6, step=7]\u001b[A\n",
      "Epoch 0:   0%|                           | 9/10822 [06:09<124:06:08, 41.32s/it, loss=1.03, lr=1.8e-6, step=8]\u001b[A\n",
      "Epoch 0:   0%|                          | 10/10822 [06:49<123:25:10, 41.09s/it, loss=1.03, lr=1.8e-6, step=8]\u001b[A\n",
      "Epoch 0:   0%|                            | 10/10822 [06:49<123:25:10, 41.09s/it, loss=1.02, lr=2e-6, step=9]\u001b[A\n",
      "Epoch 0:   0%|                            | 11/10822 [07:36<128:43:22, 42.86s/it, loss=1.02, lr=2e-6, step=9]\u001b[A\n",
      "Epoch 0:   0%|                         | 11/10822 [07:36<128:43:22, 42.86s/it, loss=1.01, lr=2.2e-6, step=10]\u001b[A\n",
      "Epoch 0:   0%|                         | 12/10822 [08:20<129:10:08, 43.02s/it, loss=1.01, lr=2.2e-6, step=10]\u001b[A\n",
      "Epoch 0:   0%|                         | 12/10822 [08:20<129:10:08, 43.02s/it, loss=1.01, lr=2.4e-6, step=11]\u001b[A\n",
      "Epoch 0:   0%|                         | 13/10822 [09:04<130:24:12, 43.43s/it, loss=1.01, lr=2.4e-6, step=11]\u001b[A\n",
      "Epoch 0:   0%|                            | 13/10822 [09:04<130:24:12, 43.43s/it, loss=1, lr=2.6e-6, step=12]\u001b[A\n",
      "Epoch 0:   0%|                            | 14/10822 [09:55<137:12:56, 45.70s/it, loss=1, lr=2.6e-6, step=12]\u001b[A\n",
      "Epoch 0:   0%|                        | 14/10822 [09:55<137:12:56, 45.70s/it, loss=0.998, lr=2.8e-6, step=13]\u001b[A\n",
      "Epoch 0:   0%|                        | 15/10822 [10:48<144:01:18, 47.98s/it, loss=0.998, lr=2.8e-6, step=13]\u001b[A\n",
      "Epoch 0:   0%|                          | 15/10822 [10:48<144:01:18, 47.98s/it, loss=0.986, lr=3e-6, step=14]\u001b[A\n",
      "Epoch 0:   0%|                          | 16/10822 [11:40<147:56:12, 49.28s/it, loss=0.986, lr=3e-6, step=14]\u001b[A\n",
      "Epoch 0:   0%|                        | 16/10822 [11:40<147:56:12, 49.28s/it, loss=0.983, lr=3.2e-6, step=15]\u001b[A\n",
      "Epoch 0:   0%|                        | 17/10822 [12:20<139:04:56, 46.34s/it, loss=0.983, lr=3.2e-6, step=15]\u001b[A\n",
      "Epoch 0:   0%|                        | 17/10822 [12:20<139:04:56, 46.34s/it, loss=0.976, lr=3.4e-6, step=16]\u001b[A\n",
      "Epoch 0:   0%|                        | 18/10822 [13:02<134:47:56, 44.92s/it, loss=0.976, lr=3.4e-6, step=16]\u001b[A\n",
      "Epoch 0:   0%|                        | 18/10822 [13:02<134:47:56, 44.92s/it, loss=0.969, lr=3.6e-6, step=17]\u001b[A\n",
      "Epoch 0:   0%|                        | 19/10822 [13:47<135:09:35, 45.04s/it, loss=0.969, lr=3.6e-6, step=17]\u001b[A\n",
      "Epoch 0:   0%|                        | 19/10822 [13:47<135:09:35, 45.04s/it, loss=0.951, lr=3.8e-6, step=18]\u001b[A\n",
      "Epoch 0:   0%|                        | 20/10822 [14:24<128:16:26, 42.75s/it, loss=0.951, lr=3.8e-6, step=18]\u001b[A\n",
      "Epoch 0:   0%|                          | 20/10822 [14:24<128:16:26, 42.75s/it, loss=0.947, lr=4e-6, step=19]\u001b[A\n",
      "Epoch 0:   0%|                          | 21/10822 [15:11<132:11:52, 44.06s/it, loss=0.947, lr=4e-6, step=19]\u001b[A\n",
      "Epoch 0:   0%|                        | 21/10822 [15:11<132:11:52, 44.06s/it, loss=0.941, lr=4.2e-6, step=20]\u001b[A\n",
      "Epoch 0:   0%|                        | 22/10822 [15:58<134:02:45, 44.68s/it, loss=0.941, lr=4.2e-6, step=20]\u001b[A\n",
      "Epoch 0:   0%|                        | 22/10822 [15:58<134:02:45, 44.68s/it, loss=0.932, lr=4.4e-6, step=21]\u001b[A\n",
      "Epoch 0:   0%|                        | 23/10822 [16:55<145:41:13, 48.57s/it, loss=0.932, lr=4.4e-6, step=21]\u001b[A\n",
      "Epoch 0:   0%|                        | 23/10822 [16:55<145:41:13, 48.57s/it, loss=0.912, lr=4.6e-6, step=22]\u001b[A\n",
      "Epoch 0:   0%|                        | 24/10822 [17:48<149:08:28, 49.72s/it, loss=0.912, lr=4.6e-6, step=22]\u001b[A\n",
      "Epoch 0:   0%|                        | 24/10822 [17:48<149:08:28, 49.72s/it, loss=0.899, lr=4.8e-6, step=23]\u001b[A\n",
      "Epoch 0:   0%|                        | 25/10822 [18:35<147:08:45, 49.06s/it, loss=0.899, lr=4.8e-6, step=23]\u001b[A\n",
      "Epoch 0:   0%|                          | 25/10822 [18:35<147:08:45, 49.06s/it, loss=0.898, lr=5e-6, step=24]\u001b[A\n",
      "Epoch 0:   0%|                          | 26/10822 [19:20<143:49:36, 47.96s/it, loss=0.898, lr=5e-6, step=24]\u001b[A\n",
      "Epoch 0:   0%|                        | 26/10822 [19:20<143:49:36, 47.96s/it, loss=0.893, lr=5.2e-6, step=25]\u001b[A\n",
      "Epoch 0:   0%|                        | 27/10822 [20:09<144:04:24, 48.05s/it, loss=0.893, lr=5.2e-6, step=25]\u001b[A\n",
      "Epoch 0:   0%|                        | 27/10822 [20:09<144:04:24, 48.05s/it, loss=0.863, lr=5.4e-6, step=26]\u001b[A\n",
      "Epoch 0:   0%|                        | 28/10822 [21:03<149:46:22, 49.95s/it, loss=0.863, lr=5.4e-6, step=26]\u001b[A\n",
      "Epoch 0:   0%|                        | 28/10822 [21:03<149:46:22, 49.95s/it, loss=0.866, lr=5.6e-6, step=27]\u001b[A\n",
      "Epoch 0:   0%|                        | 29/10822 [22:00<156:12:44, 52.10s/it, loss=0.866, lr=5.6e-6, step=27]\u001b[A\n",
      "Epoch 0:   0%|                        | 29/10822 [22:00<156:12:44, 52.10s/it, loss=0.839, lr=5.8e-6, step=28]\u001b[A\n",
      "Epoch 0:   0%|                        | 30/10822 [22:43<147:53:11, 49.33s/it, loss=0.839, lr=5.8e-6, step=28]\u001b[A\n",
      "Epoch 0:   0%|                          | 30/10822 [22:43<147:53:11, 49.33s/it, loss=0.842, lr=6e-6, step=29]\u001b[A\n",
      "Epoch 0:   0%|                          | 31/10822 [23:27<142:31:34, 47.55s/it, loss=0.842, lr=6e-6, step=29]\u001b[A\n",
      "Epoch 0:   0%|                         | 31/10822 [23:27<142:31:34, 47.55s/it, loss=0.81, lr=6.2e-6, step=30]\u001b[A\n",
      "Epoch 0:   0%|                         | 32/10822 [24:20<147:43:21, 49.29s/it, loss=0.81, lr=6.2e-6, step=30]\u001b[A\n",
      "Epoch 0:   0%|                        | 32/10822 [24:20<147:43:21, 49.29s/it, loss=0.814, lr=6.4e-6, step=31]\u001b[A\n",
      "Epoch 0:   0%|                        | 33/10822 [25:05<144:00:55, 48.05s/it, loss=0.814, lr=6.4e-6, step=31]\u001b[A\n",
      "Epoch 0:   0%|                        | 33/10822 [25:05<144:00:55, 48.05s/it, loss=0.777, lr=6.6e-6, step=32]\u001b[A\n",
      "Epoch 0:   0%|                        | 34/10822 [26:02<152:22:59, 50.85s/it, loss=0.777, lr=6.6e-6, step=32]\u001b[A\n",
      "Epoch 0:   0%|                        | 34/10822 [26:02<152:22:59, 50.85s/it, loss=0.778, lr=6.8e-6, step=33]\u001b[A\n",
      "Epoch 0:   0%|                        | 35/10822 [26:46<146:03:29, 48.74s/it, loss=0.778, lr=6.8e-6, step=33]\u001b[A\n",
      "Epoch 0:   0%|                            | 35/10822 [26:46<146:03:29, 48.74s/it, loss=0.8, lr=7e-6, step=34]\u001b[A\n",
      "Epoch 0:   0%|                            | 36/10822 [27:26<137:57:26, 46.05s/it, loss=0.8, lr=7e-6, step=34]\u001b[A\n",
      "Epoch 0:   0%|                        | 36/10822 [27:26<137:57:26, 46.05s/it, loss=0.744, lr=7.2e-6, step=35]\u001b[A\n",
      "Epoch 0:   0%|                        | 37/10822 [28:12<137:34:11, 45.92s/it, loss=0.744, lr=7.2e-6, step=35]\u001b[A\n",
      "Epoch 0:   0%|                        | 37/10822 [28:12<137:34:11, 45.92s/it, loss=0.727, lr=7.4e-6, step=36]\u001b[A\n",
      "Epoch 0:   0%|                        | 38/10822 [28:52<132:19:46, 44.18s/it, loss=0.727, lr=7.4e-6, step=36]\u001b[A\n",
      "Epoch 0:   0%|                        | 38/10822 [28:52<132:19:46, 44.18s/it, loss=0.709, lr=7.6e-6, step=37]\u001b[A\n",
      "Epoch 0:   0%|                        | 39/10822 [29:33<129:58:50, 43.40s/it, loss=0.709, lr=7.6e-6, step=37]\u001b[A\n",
      "Epoch 0:   0%|                        | 39/10822 [29:33<129:58:50, 43.40s/it, loss=0.696, lr=7.8e-6, step=38]\u001b[A\n",
      "Epoch 0:   0%|                        | 40/10822 [30:18<131:16:38, 43.83s/it, loss=0.696, lr=7.8e-6, step=38]\u001b[A\n",
      "Epoch 0:   0%|                          | 40/10822 [30:18<131:16:38, 43.83s/it, loss=0.695, lr=8e-6, step=39]\u001b[A\n",
      "Epoch 0:   0%|                          | 41/10822 [31:11<139:48:48, 46.69s/it, loss=0.695, lr=8e-6, step=39]\u001b[A\n",
      "Epoch 0:   0%|                        | 41/10822 [31:11<139:48:48, 46.69s/it, loss=0.663, lr=8.2e-6, step=40]\u001b[A\n",
      "Epoch 0:   0%|                        | 42/10822 [31:59<140:57:16, 47.07s/it, loss=0.663, lr=8.2e-6, step=40]\u001b[A\n",
      "Epoch 0:   0%|                        | 42/10822 [31:59<140:57:16, 47.07s/it, loss=0.633, lr=8.4e-6, step=41]\u001b[A\n",
      "Epoch 0:   0%|                        | 43/10822 [32:49<143:28:40, 47.92s/it, loss=0.633, lr=8.4e-6, step=41]\u001b[A\n",
      "Epoch 0:   0%|                        | 43/10822 [32:49<143:28:40, 47.92s/it, loss=0.667, lr=8.6e-6, step=42]\u001b[A\n",
      "Epoch 0:   0%|                        | 44/10822 [33:28<134:51:55, 45.05s/it, loss=0.667, lr=8.6e-6, step=42]\u001b[A\n",
      "Epoch 0:   0%|                         | 44/10822 [33:28<134:51:55, 45.05s/it, loss=0.62, lr=8.8e-6, step=43]\u001b[A\n",
      "Epoch 0:   0%|                         | 45/10822 [34:15<136:31:28, 45.61s/it, loss=0.62, lr=8.8e-6, step=43]\u001b[A\n",
      "Epoch 0:   0%|                          | 45/10822 [34:15<136:31:28, 45.61s/it, loss=0.603, lr=9e-6, step=44]\u001b[A\n",
      "Epoch 0:   0%|                          | 46/10822 [34:57<133:49:25, 44.71s/it, loss=0.603, lr=9e-6, step=44]\u001b[A\n",
      "Epoch 0:   0%|                         | 46/10822 [34:57<133:49:25, 44.71s/it, loss=0.59, lr=9.2e-6, step=45]\u001b[A\n",
      "Epoch 0:   0%|                         | 47/10822 [35:34<127:01:44, 42.44s/it, loss=0.59, lr=9.2e-6, step=45]\u001b[A\n",
      "Epoch 0:   0%|                        | 47/10822 [35:34<127:01:44, 42.44s/it, loss=0.555, lr=9.4e-6, step=46]\u001b[A\n",
      "Epoch 0:   0%|                        | 48/10822 [36:13<123:43:58, 41.34s/it, loss=0.555, lr=9.4e-6, step=46]\u001b[A\n",
      "Epoch 0:   0%|                        | 48/10822 [36:13<123:43:58, 41.34s/it, loss=0.586, lr=9.6e-6, step=47]\u001b[A\n",
      "Epoch 0:   0%|                        | 49/10822 [36:50<119:50:53, 40.05s/it, loss=0.586, lr=9.6e-6, step=47]\u001b[A\n",
      "Epoch 0:   0%|                        | 49/10822 [36:50<119:50:53, 40.05s/it, loss=0.538, lr=9.8e-6, step=48]\u001b[A\n",
      "Epoch 0:   0%|                        | 50/10822 [37:27<117:19:45, 39.21s/it, loss=0.538, lr=9.8e-6, step=48]\u001b[A\n",
      "Epoch 0:   0%|                          | 50/10822 [37:27<117:19:45, 39.21s/it, loss=0.525, lr=1e-5, step=49]\u001b[A\n",
      "Epoch 0:   0%|                          | 51/10822 [38:16<125:28:51, 41.94s/it, loss=0.525, lr=1e-5, step=49]\u001b[A\n",
      "Epoch 0:   0%|                       | 51/10822 [38:16<125:28:51, 41.94s/it, loss=0.483, lr=1.02e-5, step=50]\u001b[A\n",
      "Epoch 0:   0%|                       | 52/10822 [39:04<130:56:33, 43.77s/it, loss=0.483, lr=1.02e-5, step=50]\u001b[A\n",
      "Epoch 0:   0%|                       | 52/10822 [39:04<130:56:33, 43.77s/it, loss=0.464, lr=1.04e-5, step=51]\u001b[A\n",
      "Epoch 0:   0%|                       | 53/10822 [39:47<130:47:13, 43.72s/it, loss=0.464, lr=1.04e-5, step=51]\u001b[A\n",
      "Epoch 0:   0%|                       | 53/10822 [39:47<130:47:13, 43.72s/it, loss=0.475, lr=1.06e-5, step=52]\u001b[A\n",
      "Epoch 0:   0%|                       | 54/10822 [40:24<124:40:24, 41.68s/it, loss=0.475, lr=1.06e-5, step=52]\u001b[A\n",
      "Epoch 0:   0%|                       | 54/10822 [40:24<124:40:24, 41.68s/it, loss=0.507, lr=1.08e-5, step=53]\u001b[A\n",
      "Epoch 0:   1%|                       | 55/10822 [41:07<125:33:35, 41.98s/it, loss=0.507, lr=1.08e-5, step=53]\u001b[A\n",
      "Epoch 0:   1%|                        | 55/10822 [41:07<125:33:35, 41.98s/it, loss=0.419, lr=1.1e-5, step=54]\u001b[A\n",
      "Epoch 0:   1%|                        | 56/10822 [41:59<134:41:52, 45.04s/it, loss=0.419, lr=1.1e-5, step=54]\u001b[A\n",
      "Epoch 0:   1%|                       | 56/10822 [41:59<134:41:52, 45.04s/it, loss=0.439, lr=1.12e-5, step=55]\u001b[A\n",
      "Epoch 0:   1%|                       | 57/10822 [42:46<136:10:43, 45.54s/it, loss=0.439, lr=1.12e-5, step=55]\u001b[A\n",
      "Epoch 0:   0%|                     | 41/10822 [1:09:02<302:32:37, 101.03s/it, loss=0.699, lr=8.2e-6, step=40]\u001b[A\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m args \u001b[38;5;241m=\u001b[39m (config, model, optimizer, noise_scheduler,\n\u001b[0;32m      2\u001b[0m         dataloader, lr_scheduler)\n\u001b[1;32m----> 3\u001b[0m notebook_launcher(train_loop, args, num_processes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\accelerate\\launchers.py:221\u001b[0m, in \u001b[0;36mnotebook_launcher\u001b[1;34m(function, args, num_processes, mixed_precision, use_port, master_addr, node_rank, num_nodes)\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLaunching training on CPU.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 221\u001b[0m function(\u001b[38;5;241m*\u001b[39margs)\n",
      "Cell \u001b[1;32mIn[25], line 55\u001b[0m, in \u001b[0;36mtrain_loop\u001b[1;34m(config, model, optimizer, noise_scheduler, dataloader, lr_scheduler)\u001b[0m\n\u001b[0;32m     47\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m noise_scheduler\u001b[38;5;241m.\u001b[39madd_noise(\n\u001b[0;32m     48\u001b[0m         clean_images,\n\u001b[0;32m     49\u001b[0m         noise,\n\u001b[0;32m     50\u001b[0m         timesteps\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m accelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m---> 55\u001b[0m     noise_pred \u001b[38;5;241m=\u001b[39m model(noisy_images,\n\u001b[0;32m     56\u001b[0m                        timesteps,\n\u001b[0;32m     57\u001b[0m                        return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     58\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mmse_loss(noise_pred, noise)\n\u001b[0;32m     60\u001b[0m     accelerator\u001b[38;5;241m.\u001b[39mbackward(loss)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\diffusers\\models\\unets\\unet_2d.py:329\u001b[0m, in \u001b[0;36mUNet2DModel.forward\u001b[1;34m(self, sample, timestep, class_labels, return_dict)\u001b[0m\n\u001b[0;32m    327\u001b[0m         sample, skip_sample \u001b[38;5;241m=\u001b[39m upsample_block(sample, res_samples, emb, skip_sample)\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 329\u001b[0m         sample \u001b[38;5;241m=\u001b[39m upsample_block(sample, res_samples, emb)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# 6. post-process\u001b[39;00m\n\u001b[0;32m    332\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_norm_out(sample)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\diffusers\\models\\unets\\unet_2d_blocks.py:2544\u001b[0m, in \u001b[0;36mUpBlock2D.forward\u001b[1;34m(self, hidden_states, res_hidden_states_tuple, temb, upsample_size, scale)\u001b[0m\n\u001b[0;32m   2542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2543\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m upsampler \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsamplers:\n\u001b[1;32m-> 2544\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m upsampler(hidden_states, upsample_size, scale\u001b[38;5;241m=\u001b[39mscale)\n\u001b[0;32m   2546\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\diffusers\\models\\upsampling.py:184\u001b[0m, in \u001b[0;36mUpsample2D.forward\u001b[1;34m(self, hidden_states, output_size, scale)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv, LoRACompatibleConv) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m USE_PEFT_BACKEND:\n\u001b[1;32m--> 184\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(hidden_states, scale)\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    186\u001b[0m         hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(hidden_states)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\diffusers\\models\\lora.py:358\u001b[0m, in \u001b[0;36mLoRACompatibleConv.forward\u001b[1;34m(self, hidden_states, scale)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, scale: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlora_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;66;03m# make sure to the functional Conv2D function as otherwise torch.compile's graph will break\u001b[39;00m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;66;03m# see: https://github.com/huggingface/diffusers/pull/4315\u001b[39;00m\n\u001b[1;32m--> 358\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    359\u001b[0m             hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    360\u001b[0m         )\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m         original_outputs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    363\u001b[0m             hidden_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    364\u001b[0m         )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = (config, model, optimizer, noise_scheduler,\n",
    "        dataloader, lr_scheduler)\n",
    "notebook_launcher(train_loop, args, num_processes=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0771ac2d-91c1-4375-b9f5-108018ce307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GenConfig:\n",
    "    image_size = 64\n",
    "    model_dir = \"gen_model\"\n",
    "    output_dir = \"gen_images\"\n",
    "    seed = 0\n",
    "    eval_batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a953d4d-ec36-42ba-8f1a-e8387874c8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CANNOT FIND FINAL OR CHECKPOINT MODELS! EXITING!!!\n"
     ]
    }
   ],
   "source": [
    "config = GenConfig()\n",
    "    \n",
    "modelLoc = os.path.join(config.model_dir, \"finalModel.pt\")\n",
    "if (not os.path.exists(modelLoc)):\n",
    "    modelLoc = os.path.join(config.model_dir, \"checkpoint.pt\") #use latest checkpoint of final model does not exist\n",
    "if (not os.path.exists(modelLoc)):\n",
    "    print(\"CANNOT FIND FINAL OR CHECKPOINT MODELS! EXITING!!!\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7b31729-0731-4080-8150-83c94e49ac3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'gen_model\\\\checkpoint.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m noise_scheduler \u001b[38;5;241m=\u001b[39m DDPMScheduler()\n\u001b[0;32m     26\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(config\u001b[38;5;241m.\u001b[39moutput_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 27\u001b[0m finalModelDict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(modelLoc)\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(finalModelDict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnetwork\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     31\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m DDPMPipeline(unet\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     32\u001b[0m                         scheduler\u001b[38;5;241m=\u001b[39mnoise_scheduler)\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[0;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[0;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[1;32m~\\.conda\\envs\\cs542ml\\Lib\\site-packages\\torch\\serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gen_model\\\\checkpoint.pt'"
     ]
    }
   ],
   "source": [
    "device = (\"cuda\" if torch.cuda.is_available()\n",
    "            else \"mps\" if torch.backends.mps.is_available()\n",
    "            else \"cpu\")\n",
    "\n",
    "model = UNet2DModel(\n",
    "        in_channels = 3,\n",
    "        out_channels = 3,\n",
    "        sample_size = config.image_size,\n",
    "        layers_per_block = 2,\n",
    "        block_out_channels = (128,128,256,256,512,512),\n",
    "        down_block_types = [\n",
    "            \"DownBlock2D\",\"DownBlock2D\",\n",
    "            \"DownBlock2D\",\"DownBlock2D\",\n",
    "            \"AttnDownBlock2D\",\n",
    "            \"DownBlock2D\"\n",
    "        ],\n",
    "        up_block_types = [\n",
    "            \"UpBlock2D\",\n",
    "            \"AttnUpBlock2D\",\n",
    "            \"UpBlock2D\",\"UpBlock2D\",\"UpBlock2D\",\"UpBlock2D\"\n",
    "        ]        \n",
    ").to(device)\n",
    "\n",
    "noise_scheduler = DDPMScheduler()\n",
    "   \n",
    "os.makedirs(config.output_dir, exist_ok=True)\n",
    "finalModelDict = torch.load(modelLoc)\n",
    "   \n",
    "model.load_state_dict(finalModelDict[\"network\"])\n",
    "   \n",
    "pipeline = DDPMPipeline(unet=model,\n",
    "                        scheduler=noise_scheduler)\n",
    "   \n",
    "for i in range(1000):\n",
    "    evaluateEpoch(config, i, pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2764c011-9981-47ef-9f89-adb89d33bbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateEpoch(config, epoch, pipeline):\n",
    "    images = pipeline(\n",
    "        batch_size=config.eval_batch_size,\n",
    "        generator=torch.manual_seed(epoch)\n",
    "    ).images\n",
    "   \n",
    "    image_grid = make_image_grid(images, 1, 1)\n",
    "   \n",
    "    test_dir = os.path.join(config.output_dir)\n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "    image_grid.save(os.path.join(test_dir,\n",
    "                                    \"Image_%04d.png\" % epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08654d2-f4e0-4b5c-a261-fcf4a64492af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_fidelity as torf\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5689e0-0089-45ee-8500-69e5a844b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    metrics = torf.calculate_metrics(\n",
    "        input1=\"gen_images\",\n",
    "        input2=\"train_images\",\n",
    "        fid=True,\n",
    "        kid=True,\n",
    "        kid_subset_size=25, # Just doing this for expediency 200,\n",
    "        cuda=True)\n",
    "    print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
